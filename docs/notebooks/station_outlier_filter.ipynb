{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16473b52-64fd-425b-bab4-356708192bab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# QC protocol for Private Weather Stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957fd8e7-df3f-47d8-b57c-e60e26513338",
   "metadata": {},
   "source": [
    "This notebook presents how to use the Python package `pypwsqc`, a quality assurance protocol developed for automated private weather stations (PWS). The protocol consists of three filters; the Faulty Zero filter, the High Influx filter and the Station Outlier filter.\n",
    "\n",
    "The package is based on the original R code available at https://github.com/LottedeVos/PWSQC/.\n",
    "\n",
    "Publication: de Vos, L. W., Leijnse, H., Overeem, A., & Uijlenhoet, R. (2019). Quality control for crowdsourced personal weather stations to enable operational rainfall monitoring. Geophysical Research Letters, 46(15), 8820-8829\n",
    "\n",
    "`pypwsqc` depends on the `poligrain`, `xarray`, `pandas` and `numpy` packages. Make sure to install and import the required packages first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78857b63-6c25-4391-be95-119a6e906aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import poligrain as plg\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import pypwsqc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d852ea47-40ab-4956-ac7c-f9aaa1dee996",
   "metadata": {},
   "source": [
    "## Download example data\n",
    "\n",
    "In this example, we use an open PWS dataset from Amsterdam, called the \"AMS PWS\" dataset. By running the cell below, an example NetCDF-file will be downloaded to your current repository (if your machine is connected to the internet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b78fd5-c92b-4854-9a56-cefe8450f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -OL https://github.com/OpenSenseAction/OS_data_format_conventions/raw/main/notebooks/data/OpenSense_PWS_example_format_data.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e420966c-eba1-4a40-aa4b-e1f10e7bbe26",
   "metadata": {},
   "source": [
    "## Data preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7460be-a65e-4549-831d-f11fa418a21c",
   "metadata": {},
   "source": [
    "This package handles rainfall data as `xarray`  Datasets. The data set must have `time` and `id` dimensions, `latitude` and `longitude` as coordinates, and `rainfall` as data variable.\n",
    "\n",
    "An example of how to convert .csv data to a `xarray` dataset is found [here](https://github.com/OpenSenseAction/OS_data_format_conventions/blob/main/notebooks/PWS_example_dataset.ipynb).\n",
    "\n",
    "We now load the data set under the name  `ds_pws`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8f4054-4282-42a0-bfff-c12a55241672",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pws = xr.open_dataset(\"OpenSense_PWS_example_format_data.nc\")\n",
    "ds_pws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e154e21-f280-4fed-9512-e5f9d01c813f",
   "metadata": {},
   "source": [
    "### Reproject coordinates "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36741703-1d9a-4e5c-8fc4-e8f3d7019247",
   "metadata": {},
   "source": [
    "First we reproject the coordinates to a local metric coordinate reference system to allow for distance calculations. In the Amsterdam example we use EPSG:25832. **Remember to use a local metric reference system for your use case!** We use the function `spatial.project_point_coordinates` in the `poligrain`package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf503ba3-25b1-431a-a4cc-ed1ef75b1a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pws.coords[\"x\"], ds_pws.coords[\"y\"] = plg.spatial.project_point_coordinates(\n",
    "    x=ds_pws.longitude, y=ds_pws.latitude, target_projection=\"EPSG:25832\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3cb873-e151-4fe4-8391-48479cf0179a",
   "metadata": {},
   "source": [
    "### Create distance matrix\n",
    "\n",
    "Then, we calculate the distances between all stations in our data set. If your data set has a large number of stations this can take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9162a6c-81a7-4909-8b48-85d9b7720160",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = plg.spatial.calc_point_to_point_distances(ds_pws, ds_pws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d25c8d-47bc-4f3c-82f0-9749a0bf593f",
   "metadata": {},
   "source": [
    "### Calculate data variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8514bec-544f-4c21-ab49-83ef5d6aa10b",
   "metadata": {},
   "source": [
    "Next, we will calculate the data variables `nbrs_not_nan` and `reference` that are needed to perform the quality control. If you have already processed your data with the FZ and HI-filters, your `xarray` data set already have these variables and you can proceed to the next section.\n",
    "\n",
    "`nbrs_not_nan`:\n",
    "Number of neighbours within a specificed range `max_distance` around the station that are reporting rainfall for each time step. The selected range depends on the use case and area of interest. In this example we use 10'000 meters. \n",
    "\n",
    " `reference`:\n",
    "Median rainfall of all stations within range `max_distance` from each station.\n",
    "\n",
    "`max_distance` is called 'd' in the original publication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c375fd9b-e3d6-4c5a-ace6-e0a4339dd239",
   "metadata": {},
   "source": [
    "### Select considered range around each station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad8fb97b-976d-4011-a9ec-c03a42d89f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distance = 10e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e122f83-40dd-47d7-81f9-7d772efb93e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_pws = ds_pws.load()\n",
    "\n",
    "nbrs_not_nan = []\n",
    "reference = []\n",
    "\n",
    "for pws_id in ds_pws.id.data:\n",
    "    neighbor_ids = distance_matrix.id.data[\n",
    "        (distance_matrix.sel(id=pws_id) < max_distance)\n",
    "        & (distance_matrix.sel(id=pws_id) > 0)\n",
    "    ]\n",
    "\n",
    "    N = ds_pws.rainfall.sel(id=neighbor_ids).notnull().sum(dim=\"id\")\n",
    "    nbrs_not_nan.append(N)\n",
    "\n",
    "    median = ds_pws.sel(id=neighbor_ids).rainfall.median(dim=\"id\")\n",
    "    reference.append(median)\n",
    "\n",
    "ds_pws[\"nbrs_not_nan\"] = xr.concat(nbrs_not_nan, dim=\"id\")\n",
    "ds_pws[\"reference\"] = xr.concat(reference, dim=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eab0fb-adbf-4af9-8ccc-1dbaa9f8cecd",
   "metadata": {},
   "source": [
    "### Initialize data variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5e4ca-257d-4765-8ade-7c97494d57c9",
   "metadata": {},
   "source": [
    "We initialize data variables for the resulting SO-flags and the median pearson correlation with neighboring stations with the value -999. If the variables have the value 0 (passed the test), 1 (did not pass the test) or -1 (not enough information) after running the SO-filter, we know that these time series have been evaluated. If the value is still -999, this means that something went wrong as the data has not been processed. \n",
    "\n",
    "We also save the threshold `gamma` as a variable. In this way we can easily visualize if the median correlation with neighbors drops below this threshold, which is the condition for raising a SO-flag (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeda5019-ca1c-4e30-befc-46c10604be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b737e56e-bac6-474e-b8bd-33f9e14e9f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pws['so_flag'] = xr.DataArray(np.ones((len(ds_pws.id), len(ds_pws.time)))*-999, dims=(\"id\", \"time\"))\n",
    "ds_pws['median_corr_nbrs'] = xr.DataArray(np.ones((len(ds_pws.id), len(ds_pws.time)))*-999, dims=(\"id\", \"time\"))\n",
    "ds_pws['gamma'] = xr.DataArray(np.ones((len(ds_pws.id), len(ds_pws.time)))*gamma, dims=(\"id\", \"time\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c72972-0e02-4581-871d-e562445bf705",
   "metadata": {},
   "source": [
    "The private weather stations in your data set likely have different installation dates, and therefore different starting days of their time series. The `time` dimension of the `xarray` data set will start on the time and day that the first station was installed. Stations that were installed later will have `NaN` until their installation date. As we obviously cannot perform quality control on a station that has been installed yet, we set the SO-flag to -1 up to the first valid rainfall observation for each station. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7a557ba-84f3-49df-8d1d-aa1becd2c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each station (ID), get the index of the first non-NaN rainfall value\n",
    "first_non_nan_index = ds_pws[\"rainfall\"].notnull().argmax(dim=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ccbafe-b798-49a4-b637-6ee99062e2a3",
   "metadata": {},
   "source": [
    "## Quality control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b4f4d-a945-49f6-9fb5-d67406ca79b3",
   "metadata": {},
   "source": [
    "Now the data set is prepared to run the quality control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999a835d-f753-43f8-a53a-16b449034ba2",
   "metadata": {},
   "source": [
    "### Apply Station Outlier filter\n",
    "\n",
    "Conditions for raising Station Outlier flag:\n",
    "\n",
    "* Median of the rolling pearson correlation with all neighboring stations within range `max_distance` is less than threshold `gamma`\n",
    "* Filter cannot be applied if less than `nstat` neighbours are reporting data (SO flag is set to -1)\n",
    "*  **Filter cannot be applied if there are less than `nstat` neighbours with less than `mmatch` intervals overlapping with the evaluated station(SO flag is set to -1)**\n",
    "\n",
    "For settings for parameter `mint`, `mmatch`, `gamma`, and `nstat`, see table 1 in https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019GL083731 \n",
    "\n",
    "Note! The SO-filter is different compared with the original R-code. In its original implementation, any interval with at least `mrain` intervals of nonzero rainfall measurements is evaluated. In this implementation, only a fixed rolling window of `mint` intervals is evaluated. Therefore, the `mrain` from the orignal code is not needed. In the original publication, the variable `mint` (the evaluation period) is set to 4032. For 5-minute data, this is equivalent of two weeks. When the option of a variable evaluation period is excluded, two weeks is often too short as there might not be enough wet periods in the last two weeks to calculate the correlation. This results in a lot of '-1'-flags (filter cannot be applied). It is suggested to use a longer evaluation period, for example four weeks (`mint` = 8064 for 5-minute data).\n",
    "\n",
    "`max_distance` is called 'd' in the original publication.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f13cfb3-9b8c-4cb5-9115-8ccbebdc07e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mint = 8064  \n",
    "mmatch = 200\n",
    "gamma = 0.15 \n",
    "n_stat = 5\n",
    "max_distance = 10e3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267a65d4-fdec-4060-8fcd-d50cc2c82a9b",
   "metadata": {},
   "source": [
    "## move cells below to flagging.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cb6a87e-0640-434c-8bfa-78c7528cdb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def so_filter(da_station, da_neighbors, window_length):\n",
    "\n",
    "    # rolling pearson correlation\n",
    "    s_station = da_station.to_series()\n",
    "    s_neighbors = da_neighbors.to_series()\n",
    "    corr = s_station.rolling(window_length, min_periods= 1).corr(s_neighbors)\n",
    "    ds = xr.Dataset.from_dataframe(pd.DataFrame({'corr': corr}))\n",
    "\n",
    "    # create dataframe of neighboring stations\n",
    "    df = da_neighbors.to_dataframe()\n",
    "    df = df[\"rainfall\"].unstack(\"id\")\n",
    "\n",
    "    # boolean arrays - True if a rainy time step, False if 0 or NaN.\n",
    "    rainy_timestep_at_nbrs = (df > 0)\n",
    "    \n",
    "    # rolling sum of number of rainy timesteps in last mint period, per neighbor. \n",
    "    wet_timesteps_last_mint_period = rainy_timestep_at_nbrs.rolling(mint, min_periods=1).sum()\n",
    "    \n",
    "    # per time step and neighbor, does the nbr have more than mmatch wet time steps in the last mint period? (true/false)\n",
    "    enough_matches_per_nbr = (wet_timesteps_last_mint_period > mmatch)\n",
    "    \n",
    "    # summing how many neighbors that have enough matches per time step\n",
    "    nr_nbrs_with_enough_matches = enough_matches_per_nbr.sum(axis = 1)\n",
    "\n",
    "    ds['matches'] = xr.DataArray.from_series(nr_nbrs_with_enough_matches)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f3f09c29-d5c2-4fb6-aef4-594f5198770a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 19.4 s\n",
      "Wall time: 19.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in [100]: # range(len(ds_pws.id)):\n",
    "    \n",
    "    ds_station = ds_pws.isel(id=i)\n",
    "    pws_id = ds_station.id.values\n",
    "\n",
    "    # picking stations within max_distnance, excluding itself, for the whole duration of the time series\n",
    "    neighbor_ids = distance_matrix.id.data[(distance_matrix.sel(id=pws_id) < max_distance) & (distance_matrix.sel(id=pws_id) > 0)]\n",
    "\n",
    "    #create data set for neighbors\n",
    "    #ds_neighbors = ds_pws.sel(id=neighbor_ids).sel(time = slice('2016-05-01T00:05:00','2016-05-01T06:05:00'))\n",
    "    ds_neighbors = ds_pws.sel(id=neighbor_ids)\n",
    "\n",
    "    # if there are no observations in the time series, filter cannot be applied to the whole time series\n",
    "    if ds_pws.rainfall.sel(id=pws_id).isnull().all():\n",
    "        ds_pws.so_flag[i, :] = -1\n",
    "        ds_pws.median_corr_nbrs[i,:] = -1\n",
    "        continue\n",
    "\n",
    "    # if there are not enough stations nearby, filter cannot be applied to the whole time series\n",
    "    elif (len(neighbor_ids) < n_stat):\n",
    "        ds_pws.so_flag[i, :] = -1\n",
    "        ds_pws.median_corr_nbrs[i,:] = -1\n",
    "        continue \n",
    "        \n",
    "    else: \n",
    "\n",
    "    # run so-filter\n",
    "        ds_so_filter = so_filter(ds_station.rainfall, ds_neighbors.rainfall, window_length=mint)\n",
    "\n",
    "        median_correlation = ds_so_filter.corr.median(dim='id', skipna = True)\n",
    "        ds_pws.median_corr_nbrs[i] = median_correlation\n",
    "        \n",
    "        so_array = (median_correlation < gamma).astype(int)\n",
    "        \n",
    "    # filter can not be applied if less than n_stat neighbors have enough matches\n",
    "        ds_pws.so_flag[i] = xr.where(ds_so_filter.matches < n_stat, -1, so_array)\n",
    "\n",
    "    # Set so_flag to -1 up to first valid index\n",
    "        first_valid_time = first_non_nan_index[i].item()\n",
    "        ds_pws[\"so_flag\"][i, :first_valid_time] = -1 \n",
    "\n",
    "    # disregard warm up period\n",
    "        ds_pws.so_flag[i, first_valid_time:(first_valid_time+mint)] = -1\n",
    "        \n",
    "# ds_pws.to_netcdf('C:/Users/a002461/OPENSENSE/data/fourth_SO_flags_test.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5abcf6-4c66-420b-a0da-02e2f335c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "so_flag = pypwsqc.flagging.so_filter(\n",
    "    ds_pws,\n",
    "    distance_matrix,\n",
    "    mint = 4032,\n",
    "    mmatch = 200,\n",
    "    gamma = 0.15,\n",
    "    n_stat = 5,\n",
    "    max_distance = 10e3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f705aae-890d-4852-b4f1-03974c6b5dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so_flag = pypwsqc.flagging.so_filter(\n",
    "#    ds_pws.rainfall,\n",
    "#    ds_pws.nbrs_not_nan,\n",
    "#    ds_pws.reference,\n",
    "#    distance_matrix,\n",
    "#    mint = 4032,\n",
    "#    mrain = 100,\n",
    "#    mmatch = 200,\n",
    "#    gamma = 0.15,\n",
    "#   beta = 0.2,\n",
    "#    n_stat = 5,\n",
    "#    max_distance = 10e3,\n",
    "#)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
